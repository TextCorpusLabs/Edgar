{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducible steps to create a corpus from [EDGAR](https://www.sec.gov/edgar) 10-k filings.\n",
    "\n",
    "# Example\n",
    "\n",
    "Retrieve a single file by hand.\n",
    "\n",
    "1. Navigate to [here](https://www.sec.gov/edgar/searchedgar/companysearch)\n",
    "2. Enter \"ENV\" into the search box.\n",
    "3. Right hand side, expand \"10-K (annual reports) and 10-Q (quarterly reports)\"\n",
    "4. Get whatever is on top.\n",
    "\n",
    "As of 2024/01/03\n",
    "\n",
    "\"ENV\" is:\n",
    "\n",
    "* https://www.sec.gov/edgar/browse/?CIK=1337619\n",
    "* https://www.sec.gov/ix?doc=/Archives/edgar/data/1337619/000133761923000012/env-20221231.htm\n",
    "\n",
    "\"MSFT\" is:\n",
    "\n",
    "* https://www.sec.gov/edgar/browse/?CIK=789019\n",
    "* https://www.sec.gov/ix?doc=/Archives/edgar/data/789019/000095017023035122/msft-20230630.htm\n",
    "\n",
    "\n",
    "# Pseudocode\n",
    "\n",
    "Below is a list of the steps we take.\n",
    "Keep in mind that these steps are a 10 thousand foot view.\n",
    "The implementation will be commented to a more detailed level.\n",
    "\n",
    "1. Get the tickers from the [SEC](https://www.sec.gov/file/company-tickers)\n",
    "2. Using the retrieved data, get the accession documents for the 10-Ks (`form_type`) the past 20 (`limit`) years\n",
    "3. Using the retrieved data, get the XHTML files\n",
    "\n",
    "You can force a full re-download by deleting everything in _~/data/10-k_.\n",
    "Otherwise the script will do a checkpoint evaluation of how far it has processed.\n",
    "It will skip steps it thinks are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tickers_url = 'https://www.sec.gov/files/company_tickers.json'\n",
    "user_agent = 'TextCorpusLabs/EDGAR'\n",
    "limit = 20\n",
    "form_type = '10-K'\n",
    "\n",
    "data_folder = Path(f'./data/{form_type}')\n",
    "tickers_file = data_folder.joinpath('./tickers.csv')\n",
    "accessions_file = data_folder.joinpath('./accession.metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "1. Get the list of tickers from the SEC\n",
    "2. Convert the tickers into an array, then sort it.\n",
    "3. Save the tickers to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_tickers(tickers_file: Path, tickers_url: str, user_agent: str, ) -> pd.DataFrame:\n",
    "    if not tickers_file.exists():\n",
    "        tickers = None\n",
    "        with requests.Session() as session:\n",
    "            session.headers['User-Agent'] = user_agent\n",
    "            with session.get(tickers_url) as result:\n",
    "                if result.status_code == 200:\n",
    "                    t1 = json.loads(result.text)\n",
    "                    t2 = [x for x in t1.values()]\n",
    "                    t3 = sorted(t2, key = lambda tup: tup['ticker'])\n",
    "                    tickers = [(x['cik_str'], x['ticker'], x['title']) for x in t3]\n",
    "        if tickers is not None:\n",
    "            df = pd.DataFrame(tickers, columns = ['CIK', 'Ticker', 'Name'])\n",
    "            if not tickers_file.parent.exists():\n",
    "                tickers_file.parent.mkdir(parents = True)\n",
    "            df.to_csv(tickers_file, index = False)\n",
    "        else:\n",
    "            raise RuntimeError('Error retrieving tickers')          \n",
    "    return pd.read_csv(tickers_file) #type: ignore\n",
    "\n",
    "tickers = get_tickers(tickers_file, tickers_url, user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "For each CIK in _tickers.csv_ (Step 1)\n",
    "\n",
    "1. Get the accessions for the past 20 10-Ks\n",
    "\n",
    "Save all the accessions for all the CIKs to disk\n",
    "\n",
    "**Note 1**: Notice `tickers.CIK.unique()`.\n",
    "The data pull needs to be done on CIK, not ticker.\n",
    "A single company can have more than one ticker (AACI vs AACIU), byt only one CIK (1844817).\n",
    "\n",
    "**Note 2**: Notice `except ValueError: pass`.\n",
    "It is possible for a CIK (or ticker) to have no associated documents of a particular type(10-k).\n",
    "`get_filing_metadatas()` responds to this case by throwing an error.\n",
    "On our side, it just means skip the record.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type: ignore\n",
    "#cSpell: ignore tqdm, metadatas, dtype\n",
    "from sec_downloader import Downloader\n",
    "from tqdm.notebook import tqdm\n",
    "import sec_downloader.types as sec_t\n",
    "import typing as t\n",
    "\n",
    "def get_accession_metadata(accessions_file: Path, tickers: pd.DataFrame, form_type: str, limit: int, user_agent: str) -> pd.DataFrame:\n",
    "    if not accessions_file.exists():\n",
    "        metadata: t.List[sec_t.FilingMetadata] = []\n",
    "        downloader = Downloader(user_agent, '')\n",
    "        for cik in tqdm(tickers.CIK.unique()):\n",
    "            try:\n",
    "                t1 = downloader.get_filing_metadatas(sec_t.RequestedFilings(ticker_or_cik  = cik, form_type = form_type, limit = limit))\n",
    "                metadata.extend(t1)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        if len(metadata) > 0:\n",
    "            df = pd.DataFrame(metadata)\n",
    "            df = df[[\"cik\", \"accession_number\", \"report_date\", \"primary_doc_url\"]]\n",
    "            df = df.rename(columns={'cik': 'CIK', 'accession_number': 'Accession Number', 'report_date': 'Report Date', 'primary_doc_url': 'URL'})\n",
    "            if not accessions_file.parent.exists():\n",
    "                accessions_file.parent.mkdir(parents = True)\n",
    "            df.to_csv(accessions_file, index = False)\n",
    "        else:\n",
    "            raise RuntimeError('Error retrieving accessions')\n",
    "    return pd.read_csv(accessions_file, dtype = {'CIK': int, 'Accession Number': str, 'Report Date': str, 'URL': str}, parse_dates = ['Report Date'])\n",
    "\n",
    "accessions = get_accession_metadata(accessions_file, tickers, form_type, limit, user_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "For each accession in _accessions.csv_ (Step 2)\n",
    "\n",
    "1. Get the XHTML document\n",
    "2. save it to disk as _~/data/10-k/{year}/{cik}.{accession number}.xhtml_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cSpell: ignore tqdm\n",
    "#type: ignore\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "def get_accession_metadata(data_folder: Path, accessions: pd.DataFrame, user_agent: str) -> None:\n",
    "    @dataclass\n",
    "    class Accession:\n",
    "        CIK: int\n",
    "        AccessionNumber: str\n",
    "        ReportDate: datetime\n",
    "        URL: str\n",
    "        def __init__(self, record: t.Dict[str, t.Union[int, str, datetime]]):\n",
    "            self.CIK = record['CIK']\n",
    "            self.AccessionNumber = record['Accession Number']\n",
    "            self.ReportDate = record['Report Date']\n",
    "            self.URL = record['URL']\n",
    "    def get_filing_xhtml(session: requests.Session, accession: Accession) -> t.Union[None, str]:\n",
    "        with session.get(accession.URL) as response:\n",
    "            if response.status_code == 200:\n",
    "                return response.text\n",
    "        return None\n",
    "    def get_xhtml_file_path(data_folder: Path, accession: Accession) -> Path:\n",
    "        year = str(accession.ReportDate.year)\n",
    "        year = year if year != 'nan' else '0000'\n",
    "        return data_folder.joinpath(f'{year}/{accession.CIK}.{accession.AccessionNumber}.xhtml')\n",
    "    with requests.Session() as session:\n",
    "        session.headers['User-Agent'] = user_agent\n",
    "        for accession in tqdm([Accession(x) for x in accessions.to_dict('records')]): \n",
    "            xhtml_file = get_xhtml_file_path(data_folder, accession)\n",
    "            if not xhtml_file.parent.exists():\n",
    "                xhtml_file.parent.mkdir(parents = True)\n",
    "            if xhtml_file.exists():\n",
    "                continue\n",
    "            xhtml = get_filing_xhtml(session, accession)\n",
    "            if xhtml is None:\n",
    "                print(f'{accession.CIK}.{accession.AccessionNumber} failed')\n",
    "            else:\n",
    "                with open(xhtml_file, mode = 'w') as fp:\n",
    "                    fp.write(xhtml)\n",
    "\n",
    "get_accession_metadata(data_folder, accessions, user_agent)"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "minimal",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
