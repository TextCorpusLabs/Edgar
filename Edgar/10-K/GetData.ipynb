{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducible steps for getting 10-k filings from [EDGAR](https://www.sec.gov/edgar).\n",
    "\n",
    "You will need the latest copy of the modules.\n",
    "\n",
    "1. [sec-downloader](https://github.com/Elijas/sec-downloader)\n",
    "2. [sec-parser](https://github.com/alphanome-ai/sec-parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (23.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sec-downloader in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: sec-edgar-downloader in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-downloader) (5.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-edgar-downloader->sec-downloader) (2.31.0)\n",
      "Requirement already satisfied: pyrate-limiter>=3.1.0 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-edgar-downloader->sec-downloader) (3.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->sec-edgar-downloader->sec-downloader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->sec-edgar-downloader->sec-downloader) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->sec-edgar-downloader->sec-downloader) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->sec-edgar-downloader->sec-downloader) (2023.11.17)\n",
      "Requirement already satisfied: sec-parser in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.54.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-parser) (4.12.2)\n",
      "Requirement already satisfied: cssutils<3.0.0,>=2.9.0 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-parser) (2.9.0)\n",
      "Requirement already satisfied: frozendict<3.0.0,>=2.3.8 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-parser) (2.3.10)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-parser) (0.7.2)\n",
      "Requirement already satisfied: lxml<5.0.0,>=4.9.3 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-parser) (4.9.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-parser) (2.1.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-parser) (0.9.0)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.4.1 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sec-parser) (3.4.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.2->sec-parser) (2.5)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->sec-parser) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->sec-parser) (1.1.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->sec-parser) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->sec-parser) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->sec-parser) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->sec-parser) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\19789\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->sec-parser) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sec-downloader\n",
    "!pip install sec-parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "1. Navigate to [here](https://www.sec.gov/edgar/searchedgar/companysearch)\n",
    "2. Enter \"ENV\" into the search box.\n",
    "3. Right hand side, expand \"10-K (annual reports) and 10-Q (quarterly reports)\"\n",
    "4. Get whatever is on top.\n",
    "5. Scroll to \"Item 7\"\n",
    "\n",
    "As of 2024/01/03\n",
    "\n",
    "\"ENV\" is:\n",
    "\n",
    "* https://www.sec.gov/edgar/browse/?CIK=1337619\n",
    "* https://www.sec.gov/ix?doc=/Archives/edgar/data/1337619/000133761923000012/env-20221231.htm\n",
    "* pages 38-65\n",
    "\n",
    "\"MSFT\" is:\n",
    "\n",
    "* https://www.sec.gov/edgar/browse/?CIK=789019\n",
    "* https://www.sec.gov/ix?doc=/Archives/edgar/data/789019/000095017023035122/msft-20230630.htm\n",
    "* pages 40-57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "\n",
    "1. Get all the `symbols` in _symbols.csv_\n",
    "2. For each `symbol` in `symbols`\n",
    "   1. If _corpus/raw_ is missing the xhtml associated with the `symbol`, download it\n",
    "3. For each xhtml  _corpus/raw_\n",
    "   1. Get the element IDs associated with Item 7 and 7A\n",
    "   2. TODO: Collect all the text inside [Item 7, Item 7A), save it to _corpus/text_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sec_downloader import Downloader\n",
    "from pathlib import Path\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_file = Path('./symbols.csv')\n",
    "raw_files = Path('./corpus/raw')\n",
    "company_name = 'SokpheanalHuynh'\n",
    "email_address = 'sokpheanal.huynh@gmail.com'\n",
    "\n",
    "if not raw_files.exists():\n",
    "    raw_files.mkdir(parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving AACT...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find any filings: AACT of type 10-K",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieving \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m xhtml \u001b[38;5;241m=\u001b[39m \u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_filing_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m10-K\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(xhtml_file, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m     16\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(xhtml)\n",
      "File \u001b[1;32mc:\\Users\\19789\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sec_downloader\\core.py:98\u001b[0m, in \u001b[0;36mDownloader.get_filing_html\u001b[1;34m(self, query, ticker, form)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m query, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Either query or ticker and form must be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_filing_metadatas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     99\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_filing(url\u001b[38;5;241m=\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mprimary_doc_url)\n\u001b[0;32m    100\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(html)\n",
      "File \u001b[1;32mc:\\Users\\19789\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sec_downloader\\core.py:57\u001b[0m, in \u001b[0;36mDownloader.get_filing_metadatas\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     55\u001b[0m         query \u001b[38;5;241m=\u001b[39m RequestedFilings\u001b[38;5;241m.\u001b[39mfrom_string(query)\n\u001b[1;32m---> 57\u001b[0m     new_metadatas \u001b[38;5;241m=\u001b[39m \u001b[43mget_latest_filings_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticker_to_cik_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ticker_to_cik_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_metadatas\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\19789\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sec_downloader\\sec_edgar_downloader_fork.py:77\u001b[0m, in \u001b[0;36mget_latest_filings_metadata\u001b[1;34m(requested, user_agent, ticker_to_cik_mapping)\u001b[0m\n\u001b[0;32m     71\u001b[0m     form_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(Downloader\u001b[38;5;241m.\u001b[39msupported_forms)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequested\u001b[38;5;241m.\u001b[39mform_type\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m forms are not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease choose from the following: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mform_options\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m     )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_metadatas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcik\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcik\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mticker_or_cik\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequested\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mticker_or_cik\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mform_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequested\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mform_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\19789\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sec_downloader\\sec_edgar_downloader_fork.py:196\u001b[0m, in \u001b[0;36m_get_metadatas\u001b[1;34m(cik, user_agent, limit, ticker_or_cik, accession_number, form_type)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found_metadatas:\n\u001b[0;32m    195\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find any filings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(found_metadatas) \u001b[38;5;241m>\u001b[39m limit:\n\u001b[0;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound more than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlimit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m filings, actual count is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(found_metadatas)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not find any filings: AACT of type 10-K"
     ]
    }
   ],
   "source": [
    "with open(symbol_file, mode = 'r', encoding = 'utf-8') as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    next(reader)\n",
    "    symbols = [row[0] for row in reader]\n",
    "\n",
    "dl = Downloader(company_name, email_address)\n",
    "for symbol in symbols:\n",
    "    if symbol.startswith('#'):\n",
    "        continue\n",
    "    xhtml_file = raw_files.joinpath(f'{symbol}.xhtml')\n",
    "    if xhtml_file.exists():\n",
    "        continue\n",
    "    print(f'Retrieving {symbol}...')\n",
    "    xhtml = dl.get_filing_html(ticker = symbol, form = \"10-K\")\n",
    "    with open(xhtml_file, mode = 'wb') as fp:\n",
    "        fp.write(xhtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_ids(node: etree.Element) -> tuple[str, str]:\n",
    "    # you need to include the NS in every part of the `xpath`\n",
    "    # https://stackoverflow.com/questions/38936185/etree-xpath-return-entire-html-instead-of-text\n",
    "    ns_map = {'x':'http://www.w3.org/1999/xhtml'}\n",
    "    xpaths = [\n",
    "        \".//x:table/x:tr/x:td//*[contains(text(),'Financial Condition and Results of Operations')]\",\n",
    "        \"ancestor-or-self::x:a[contains(@href, '#')]\",\n",
    "        \"ancestor::x:tr/following-sibling::x:tr/x:td//x:a[contains(@href, '#')]\"]\n",
    "    t1: etree.Element = node.xpath(xpaths[0], namespaces = ns_map)[0]\n",
    "    t1_href: str = t1.xpath(xpaths[1], namespaces = ns_map)[0].attrib['href']\n",
    "    t2_href: str = t1.xpath(xpaths[2], namespaces = ns_map)[0].attrib['href']\n",
    "    return t1_href, t2_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(encoding = 'utf-8', recover = True, ns_clean = True)\n",
    "for xhtml_file in raw_files.iterdir():\n",
    "    print(f'Parsing {xhtml_file.name}...')\n",
    "    with open(xhtml_file, mode = 'rb') as fp:\n",
    "        xhtml = fp.read()\n",
    "    root: etree.Element = etree.fromstring(xhtml, parser)\n",
    "    ids = get_ref_ids(root)\n",
    "    print(ids[0])\n",
    "    print(ids[1])"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "minimal",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
